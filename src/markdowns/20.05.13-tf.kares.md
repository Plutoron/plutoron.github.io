网路搭建 八股

* import 相关 模块
* 读取 训练 数据 / 测试数据
* 在 Sequential 中 逐层描述网络 (tf.keras.models.Sequential) 相当于走一遍前向传播

```
拉直层：tf.keras.layers.Flatten() 将数据拉直为 一维数组

全联接层：tf.keras.layers.Dense(神经元个数, activation = "激活函数", kernel_regulation = "那种正则化")

activation 可选 relu softmax sigmoid tanh
kernal_regulation 可选 tf.keras.regularizers.l1()

卷积层：tf.keras.layers.Conv2D(filters = "卷积核个数", kernel_size = "卷积核大小", strides = "步长", padding = "valid / same")

LSTM层：tf.keras.layers.LSTM()
```
在Keras中，您可以组装图层来构建模型。 模型（通常）是图层图。 最常见的模型类型是一堆层：tf.keras.Sequential 模型。
构建一个简单的全连接网络（即多层感知器）：
```
model = keras.Sequential()
# Adds a densely-connected layer with 64 units to the model:
model.add(keras.layers.Dense(64, activation='relu'))
# Add another:
model.add(keras.layers.Dense(64, activation='relu'))
# Add a softmax layer with 10 output units:
model.add(keras.layers.Dense(10, activation='softmax'))
```
```
# Create a sigmoid layer:
layers.Dense(64, activation='sigmoid')
# Or:
layers.Dense(64, activation=tf.sigmoid)

# A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:
layers.Dense(64, kernel_regularizer=keras.regularizers.l1(0.01))
# A linear layer with L2 regularization of factor 0.01 applied to the bias vector:
layers.Dense(64, bias_regularizer=keras.regularizers.l2(0.01))

# A linear layer with a kernel initialized to a random orthogonal matrix:
layers.Dense(64, kernel_initializer='orthogonal')
# A linear layer with a bias vector initialized to 2.0s:
layers.Dense(64, bias_initializer=keras.initializers.constant(2.0))
```

* 在 compile 中配置训练方法 model.compile(optimizer = "优化器", loss = "损失函数", metrics = "评测指标") 

```
optimizer 可选:
'sdg' or tf.keras.optimizers.SDG(lr = "学习率", momentum = "动量参数")
'adagrad' or tf.keras.optimizers.Adagrad(lr = "学习率")
'adadelta' or tf.keras.optimizers.Adadelta(lr = "学习率")
'adam' or tf.teras.optimizers.Adam(lr = "学习率", beta_1 = 0.9, beta_2 = 0.999)

loss 可选: 
'mse' or tf.keras.losses.MeanSquaredError()
[稀疏分类交叉熵](https://tensorflow.google.cn/versions/r2.0/api_docs/python/tf/keras/losses/SparseCategoricalCrossentropy) 'sparse_categorical_corossentropy' or tf.keras.losses.SparseCategoricalCorossentropy(from_logits=False, reduction=losses_utils.ReductionV2.AUTO,
    name='sparse_categorical_crossentropy') 
form_logits 表示是否不经概率分布 输出 （即softmax）

metrics 可选: 
'accuracy' 准确率 y_ 和 y 都是 数值 y_ = [1] y = [1]
'categorical_accuracy' y_ 和 y 都是 独热码形式（即 概率分布） 如 y_ = [0,1,0] y = [0.1, 0.8, 0.1]
'sparse_categorical_accuracy' y_ 是 数值 y 是独热码（概率分布），如 y_ = [1] y = [0.1, 0.8, 0.1]

```

```
# Configure a model for mean-squared error regression.
  model.compile(optimizer=tf.train.AdamOptimizer(0.01),
                loss='mse',       # mean squared error
                metrics=['mae'])  # mean absolute error

# Configure a model for categorical classification.
model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),
              loss=keras.losses.categorical_crossentropy,
              metrics=[keras.metrics.categorical_accuracy])
```

* model.fit 训练数据

```
model.fit(训练集的输入特征, 训练集的标签, batch_size=, epoches=, validation_data=(测试集的输入特征, 测试集的标签), validation_split=从训练集划分多少比例给测试集, validation_freq=多少次epoch测试一次)
```

```
epochs：训练多少轮。（小批量）
batch_size：当传递NumPy数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。 此整数指定每个批次的大小。 请注意，如果样本总数不能被批量大小整除，则最后一批可能会更小。
validation_data：在对模型进行原型设计时，您希望轻松监控其在某些验证数据上的性能。 传递这个参数 - 输入和标签的元组 - 允许模型在每个epoch的末尾以传递数据的推理模式显示损失和度量。
```
```
import numpy as np

data = np.random.random((1000, 32))
labels = np.random.random((1000, 10))

val_data = np.random.random((100, 32))
val_labels = np.random.random((100, 10))

model.fit(data, labels, epochs=10, batch_size=32,
          validation_data=(val_data, val_labels))
```